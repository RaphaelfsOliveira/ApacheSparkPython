{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KccqfD8ujL3K"
      },
      "source": [
        "# Começando o Trabalho\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyAh7l9hGlHq"
      },
      "source": [
        "## Apache Spark - Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy3ApfOoGlHt"
      },
      "source": [
        "### [Apache Spark](https://spark.apache.org/)\n",
        "\n",
        "Apache Spark é uma plataforma de computação em *cluster* que fornece uma API para programação distribuída para processamento de dados em larga escala, semelhante ao modelo *MapReduce*, mas projetada para ser rápida para consultas interativas e algoritmos iterativos.\n",
        "\n",
        "O Spark permite que você distribua dados e tarefas em clusters com vários nós. Imagine cada nó como um computador separado. A divisão dos dados torna mais fácil o trabalho com conjuntos de dados muito grandes porque cada nó funciona processa apenas uma parte parte do volume total de dados.\n",
        "\n",
        "O Spark é amplamente utilizado em projetos analíticos nas seguintes frentes:\n",
        "\n",
        "- Preparação de dados\n",
        "- Modelos de machine learning\n",
        "- Análise de dados em tempo real"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc3Adto4jWDj"
      },
      "source": [
        "### [PySpark](https://spark.apache.org/docs/3.1.2/api/python/index.html)\n",
        "\n",
        "PySpark é uma interface para Apache Spark em Python. Ele não apenas permite que você escreva aplicativos Spark usando APIs Python, mas também fornece o *shell* PySpark para analisar interativamente seus dados em um ambiente distribuído. O PySpark oferece suporte à maioria dos recursos do Spark, como Spark SQL, DataFrame, Streaming, MLlib (Machine Learning) e Spark Core.\n",
        "\n",
        "<center><img src=\"https://caelum-online-public.s3.amazonaws.com/2273-introducao-spark/01/img-001.png\"/></center>\n",
        "\n",
        "#### Spark SQL e DataFrame\n",
        "\n",
        "Spark SQL é um módulo Spark para processamento de dados estruturados. Ele fornece uma abstração de programação chamada DataFrame e também pode atuar como mecanismo de consulta SQL distribuído.\n",
        "\n",
        "#### Spark Streaming\n",
        "\n",
        "Executando em cima do Spark, o recurso de *streaming* no Apache Spark possibilita o uso de poderosas aplicações interativas e analíticas em *streaming* e dados históricos, enquanto herda a facilidade de uso do Spark e as características de tolerância a falhas.\n",
        "\n",
        "#### Spark MLlib\n",
        "\n",
        "Construído sobre o Spark, MLlib é uma biblioteca de aprendizado de máquina escalonável que fornece um conjunto uniforme de APIs de alto nível que ajudam os usuários a criar e ajustar *pipelines* de aprendizado de máquina práticos.\n",
        "\n",
        "#### Spark Core\n",
        "\n",
        "Spark Core é o mecanismo de execução geral subjacente para a plataforma Spark sobre o qual todas as outras funcionalidades são construídas. Ele fornece um RDD (*Resilient Distributed Dataset*) e recursos de computação na memória."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh-9oWn7GlHw"
      },
      "source": [
        "## Utilizando o Spark no Windows\n",
        "\n",
        "[fonte](https://spark.apache.org/docs/3.1.2/api/python/getting_started/install.html)\n",
        "\n",
        "#### Passo 1 - Instalando o Java\n",
        "\n",
        "O PySpark requer a instalação do Java na versão 7 ou superior. Obtenha a versão mais recente clicando [aqui](https://www.java.com/pt-BR/download/). Para verificar a versão que está instalada em sua máquina execute a seguinte linha de código no seu *prompt*:\n",
        "\n",
        "```\n",
        "java -version\n",
        "```\n",
        "\n",
        "#### Passo 2 - Instalando o Python\n",
        "\n",
        "O Python deve ser instalado em sua versão 2.6 ou superior. Para obter a versão mais recente clique [aqui](https://www.python.org/downloads/windows/). Para verificar a versão do Python que está instalada em sua máquina digite o seguinte comando em seu *prompt*:\n",
        "\n",
        "```\n",
        "python --version\n",
        "```\n",
        "\n",
        "#### Passo 3 - Instalando o Apache Spark \n",
        "\n",
        "Selecione a versão mais estável clicando [aqui](http://spark.apache.org/downloads.html). Na criação deste projeto utilizamos a versão do Spark **3.1.2** e como tipo de pacote selecionamos **Pre-built for Apache Hadoop 2.7**.\n",
        "\n",
        "Para instalar o Apache Spark não é necessário executar um instalador, basta descomprimir os arquivos em uma pasta de sua escolha.\n",
        "\n",
        "<font color=red>Obs.: certifique-se de que o caminho onde os arquivos do Spark foram armazenados não contenham espaços (ex.: **\"C:\\spark\\spark-3.1.2-bin-hadoop2.7\"**).</font>\n",
        "\n",
        "Para testar o funcionamento do Spark execute os comandos abaixo em seu *prompt* de comando. Esses comandos assumem que você extraiu os arquivos do Spark na pasta **\"C:\\spark\\\"**.\n",
        "\n",
        "```\n",
        "cd C:\\spark\\spark-3.1.2-bin-hadoop2.7\n",
        "```\n",
        "\n",
        "```\n",
        "bin\\pyspark\n",
        "```\n",
        "\n",
        "O comando acima inicia o *shell* do PySpark que permite trabalhar interativamente com o Spark.\n",
        "\n",
        "Para sair basta digitar `exit()` e logo depois presionar *Enter*. Para voltar ao *prompt* pressione *Enter* novamente.\n",
        "\n",
        "#### Passo 4 - Instalando o findspark\n",
        "\n",
        "```\n",
        "pip install findspark\n",
        "```\n",
        "\n",
        "#### Passo 5 - Instalando o winutils\n",
        "\n",
        "Os arquivos do Spark não incluem o utilitário **winutils.exe** que é utilizado pelo Spark no Windows. Se não informar onde o Spark deve procurar este utilitário, veremos alguns erros no console e também não conseguiremos executar *scripts* Python utilizando o utilitário `spark-submit`.\n",
        "\n",
        "Faça o [download](https://github.com/steveloughran/winutils) para a versão do Hadoop para a qual sua instalação do Spark foi construída. Em nosso exemplo foi utilizada a [versão 2.7](https://github.com/steveloughran/winutils/tree/master/hadoop-2.7.1/bin). Faça o *download* apenas do arquivo **winutils.exe**.\n",
        "\n",
        "Crie a pasta **\"hadoop\\bin\"** dentro da pasta que contém os arquivos do Spark (em nosso exemplo **\"C:\\spark\\spark-3.1.2-bin-hadoop2.7\"**) e copie o arquivo **winutils.exe** para dentro desta pasta.\n",
        "\n",
        "Crie duas variáveis de ambiente no seu Windows. A primeira chamada **SPARK_HOME** que aponta para a pasta onde os arquivos Spark foram armazenados (em nosso exemplo **\"C:\\spark\\spark-3.1.2-bin-hadoop2.7\"**). A segunda chamada **HADOOP_HOME** que aponta para **%SPARK_HOME%\\hadoop** (assim podemos modificar **SPARK_HOME** sem precisar alterar **HADOOP_HOME**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_pds0odi1Rj"
      },
      "source": [
        "## Utilizando o Spark no Google Colab\n",
        "\n",
        "Para facilitar o desenvolvimento de nosso projeto neste curso vamos utilizar o Google Colab como ferramenta e para configurar o PySpark basta executar os comandos abaixo na própria célula do seu *notebook*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "JmcO4uWZ3OLO"
      },
      "outputs": [],
      "source": [
        "# instalar as dependências para usar no Google Colab\n",
        "# !apt-get update -qq\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# !wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
        "# !tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "# !pip3 install findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "_4Z_1m0z3sPJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/Cellar/apache-spark/3.3.1/libexec\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/local/Cellar/openjdk@11/11.0.16.1/libexec/openjdk.jdk/Contents/Home\"\n",
        "\n",
        "# instalado via homebrew MacOs\n",
        "os.environ[\"SPARK_HOME\"] = \"/usr/local/Cellar/apache-spark/3.3.1/libexec\"\n",
        "\n",
        "# shell command for spark\n",
        "# pyspark -c spark.driver.bindAddress=127.0.0.1\n",
        "\n",
        "print(os.environ[\"SPARK_HOME\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "kqdft9fpGlH0"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZNca7Pjgqf"
      },
      "source": [
        "# Carregamento de Dados\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGNS075GGlH0"
      },
      "source": [
        "## [SparkSession](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.SparkSession.html)\n",
        "\n",
        "O ponto de entrada para programar o Spark com a API Dataset e DataFrame.\n",
        "\n",
        "Uma SparkSession pode ser utilizada para criar DataFrames, registrar DataFrames como tabelas, executar consultas SQL em tabelas, armazenar em cache e ler arquivos parquet. Para criar uma SparkSession, use o seguinte padrão de construtor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "yayRGdn_GlH1"
      },
      "outputs": [
        {
          "ename": "ConnectionRefusedError",
          "evalue": "[Errno 61] Connection refused",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[139], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39;49mbuilder \\\n\u001b[1;32m      2\u001b[0m     \u001b[39m.\u001b[39;49mmaster(\u001b[39m'\u001b[39;49m\u001b[39mlocal[*]\u001b[39;49m\u001b[39m'\u001b[39;49m) \\\n\u001b[1;32m      3\u001b[0m     \u001b[39m.\u001b[39;49mconfig(\u001b[39m\"\u001b[39;49m\u001b[39mspark.driver.host\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m127.0.0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[39m.\u001b[39;49mconfig(\u001b[39m\"\u001b[39;49m\u001b[39mspark.driver.bindAddress\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m127.0.0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[39m.\u001b[39;49mappName(\u001b[39m\"\u001b[39;49m\u001b[39mIniciando com Spark\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[39m.\u001b[39;49mgetOrCreate()\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/session.py:275\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     session \u001b[39m=\u001b[39m SparkSession(sc, options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[1;32m    273\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[39mgetattr\u001b[39m(\n\u001b[0;32m--> 275\u001b[0m         \u001b[39mgetattr\u001b[39;49m(session\u001b[39m.\u001b[39;49m_jvm, \u001b[39m\"\u001b[39;49m\u001b[39mSparkSession$\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39mMODULE$\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )\u001b[39m.\u001b[39mapplyModifiableSettings(session\u001b[39m.\u001b[39m_jsparkSession, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options)\n\u001b[1;32m    277\u001b[0m \u001b[39mreturn\u001b[39;00m session\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1709\u001b[0m, in \u001b[0;36mJVMView.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m UserHelpAutoCompletion\u001b[39m.\u001b[39mKEY:\n\u001b[1;32m   1707\u001b[0m     \u001b[39mreturn\u001b[39;00m UserHelpAutoCompletion()\n\u001b[0;32m-> 1709\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gateway_client\u001b[39m.\u001b[39;49msend_command(\n\u001b[1;32m   1710\u001b[0m     proto\u001b[39m.\u001b[39;49mREFLECTION_COMMAND_NAME \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1711\u001b[0m     proto\u001b[39m.\u001b[39;49mREFL_GET_UNKNOWN_SUB_COMMAND_NAME \u001b[39m+\u001b[39;49m name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_id \u001b[39m+\u001b[39;49m\n\u001b[1;32m   1712\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m proto\u001b[39m.\u001b[39;49mEND_COMMAND_PART)\n\u001b[1;32m   1713\u001b[0m \u001b[39mif\u001b[39;00m answer \u001b[39m==\u001b[39m proto\u001b[39m.\u001b[39mSUCCESS_PACKAGE:\n\u001b[1;32m   1714\u001b[0m     \u001b[39mreturn\u001b[39;00m JavaPackage(name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gateway_client, jvm_id\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
        "    .appName(\"Iniciando com Spark\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PizPNqbmCuSM"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://127.0.0.1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Iniciando com Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x1152bcc10>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbOcx1oXGlH4"
      },
      "source": [
        "## DataFrames com Spark\n",
        "\n",
        "\n",
        "### Interfaces Spark\n",
        "\n",
        "Existem três interfaces principais do Apache Spark que você deve conhecer: Resilient Distributed Dataset, DataFrame e Dataset.\n",
        "\n",
        "- **Resilient Distributed Dataset**: A primeira abstração do Apache Spark foi o Resilient Distributed Dataset (RDD). É uma interface para uma sequência de objetos de dados que consiste em um ou mais tipos localizados em uma coleção de máquinas (um cluster). Os RDDs podem ser criados de várias maneiras e são a API de “nível mais baixo” disponível. Embora esta seja a estrutura de dados original do Apache Spark, você deve se concentrar na API DataFrame, que é um superconjunto da funcionalidade RDD. A API RDD está disponível nas linguagens Java, Python e Scala.\n",
        "\n",
        "- **DataFrame**: Trata-se de um conceito similar ao DataFrame que você pode estar familiarizado como o pacote pandas do Python e a linguagem R . A API DataFrame está disponível nas linguagens Java, Python, R e Scala.\n",
        "\n",
        "- **Dataset**: uma combinação de DataFrame e RDD. Ele fornece a interface digitada que está disponível em RDDs enquanto fornece a conveniência do DataFrame. A API Dataset está disponível nas linguagens Java e Scala.\n",
        "\n",
        "Em muitos cenários, especialmente com as otimizações de desempenho incorporadas em DataFrames e Datasets, não será necessário trabalhar com RDDs. Mas é importante entender a abstração RDD porque:\n",
        "\n",
        "- O RDD é a infraestrutura subjacente que permite que o Spark seja executado com tanta rapidez e forneça a linhagem de dados.\n",
        "\n",
        "- Se você estiver mergulhando em componentes mais avançados do Spark, pode ser necessário usar RDDs.\n",
        "\n",
        "- As visualizações na Spark UI fazem referência a RDDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpFfzZN0GlH5"
      },
      "outputs": [],
      "source": [
        "data = [('Zeca','35'), ('Eva', '29')]\n",
        "colNames = ['Nome', 'Idade']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3APKGkAlGlH5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[Nome: string, Idade: string]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame(data=data, schema=colNames)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyBW_ff-JMYs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+\n",
            "|Nome|Idade|\n",
            "+----+-----+\n",
            "|Zeca|   35|\n",
            "| Eva|   29|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nome</th>\n",
              "      <th>Idade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zeca</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Eva</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Nome Idade\n",
              "0  Zeca    35\n",
              "1   Eva    29"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXVfnTIHGlH3"
      },
      "source": [
        "## Projeto\n",
        "\n",
        "Nosso projeto consiste em ler, manipular, tratar e salvar um conjunto de dados volumosos utilizando como ferramenta o Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCYYVAtjhMa7"
      },
      "source": [
        "## Carregamento de dados\n",
        "\n",
        "### Dados Públicos CNPJ\n",
        "#### Receita Federal\n",
        "\n",
        "> [Empresas](https://caelum-online-public.s3.amazonaws.com/2273-introducao-spark/01/empresas.zip)\n",
        "> \n",
        "> [Estabelecimentos](https://caelum-online-public.s3.amazonaws.com/2273-introducao-spark/01/estabelecimentos.zip)\n",
        "> \n",
        "> [Sócios](https://caelum-online-public.s3.amazonaws.com/2273-introducao-spark/01/socios.zip)\n",
        "\n",
        "[Fonte original dos dados](https://www.gov.br/receitafederal/pt-br/assuntos/orientacao-tributaria/cadastros/consultas/dados-publicos-cnpj)\n",
        "\n",
        "---\n",
        "[property SparkSession.read](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.SparkSession.read.html)\n",
        "\n",
        "[DataFrameReader.csv(*args)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrameReader.csv.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f6bwFADGlH6"
      },
      "source": [
        "### Carregando os dados das empresas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sffAOcMQt_aR"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "path = './datalake/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unzipAndcreateDataFrameSpark(path: str, fileName: str):\n",
        "    pathFile = '{path}{fileName}'.format(path=path, fileName=fileName)\n",
        "    \n",
        "    try:\n",
        "        zipfile.ZipFile('{}.zip'.format(pathFile), 'r').extractall(path)\n",
        "    except FileNotFoundError as error: \n",
        "        print(f\"Não tem o {pathFile}.zip na pasta {path}\")\n",
        "\n",
        "    try:\n",
        "        return spark.read.csv(pathFile, sep=';', inferSchema=True)\n",
        "    except FileNotFoundError as error: \n",
        "        print(f\"Não a pasta {pathFile} para transformar em DataFrame\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RVsaljf8mus"
      },
      "outputs": [],
      "source": [
        "zipfile.ZipFile('{}empresas.zip'.format(path), 'r').extractall(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "path_emp = '{}empresas'.format(path)\n",
        "dfEmp = spark.read.csv(path_emp, sep=';', inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rDKf8L-GlH6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4585679"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count de empresas com dataframe spark\n",
        "dfEmp.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0QOCzKVGlH7"
      },
      "source": [
        "## Faça como eu fiz: Estabelecimentos e Sócios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DXanOaDk1Hc"
      },
      "source": [
        "### Carregando os dados dos estabelecimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIwhrJTIGlH7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Não tem o ./datalake/estabelecimentos.zip na pasta ./datalake/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "dfEstab = unzipAndcreateDataFrameSpark(path, 'estabelecimentos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hpfe_ApWGlH7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4836219"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEstab.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOylSh6PGlH8"
      },
      "source": [
        "### Carregando os dados dos sócios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdBuLfZkGlH7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Não tem o ./datalake/socios.zip na pasta ./datalake/\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "dfSoc = unzipAndcreateDataFrameSpark(path, 'socios')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2046430"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfSoc.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyeUU1CsGlH9"
      },
      "source": [
        "# Manipulando os Dados\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vvN_LyAGlH9"
      },
      "source": [
        "## Operações básicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc8_B1H8iNkX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_c0</th>\n",
              "      <th>_c1</th>\n",
              "      <th>_c2</th>\n",
              "      <th>_c3</th>\n",
              "      <th>_c4</th>\n",
              "      <th>_c5</th>\n",
              "      <th>_c6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306</td>\n",
              "      <td>FRANCAMAR REFRIGERACAO TECNICA S/C LTDA</td>\n",
              "      <td>2240</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1355</td>\n",
              "      <td>BRASILEIRO &amp; OLIVEIRA LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4820</td>\n",
              "      <td>REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...</td>\n",
              "      <td>3034</td>\n",
              "      <td>32</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5347</td>\n",
              "      <td>ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS</td>\n",
              "      <td>2135</td>\n",
              "      <td>50</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6846</td>\n",
              "      <td>BADU E FILHOS TECIDOS LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>4000,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    _c0                                                _c1   _c2  _c3  \\\n",
              "0   306            FRANCAMAR REFRIGERACAO TECNICA S/C LTDA  2240   49   \n",
              "1  1355                         BRASILEIRO & OLIVEIRA LTDA  2062   49   \n",
              "2  4820  REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...  3034   32   \n",
              "3  5347       ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS  2135   50   \n",
              "4  6846                         BADU E FILHOS TECIDOS LTDA  2062   49   \n",
              "\n",
              "       _c4  _c5   _c6  \n",
              "0     0,00    1  None  \n",
              "1     0,00    5  None  \n",
              "2     0,00    5  None  \n",
              "3     0,00    5  None  \n",
              "4  4000,00    1  None  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEmp.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f7djxh5GlH9"
      },
      "source": [
        "### Renomeando as colunas do DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg0w9tDlGlH-"
      },
      "outputs": [],
      "source": [
        "empresasColNames = ['cnpj_basico', 'razao_social_nome_empresarial', 'natureza_juridica', 'qualificacao_do_responsavel', 'capital_social_da_empresa', 'porte_da_empresa', 'ente_federativo_responsavel']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gYSVAgPk2h8"
      },
      "outputs": [],
      "source": [
        "for index, colName in enumerate(empresasColNames):\n",
        "    dfEmp = dfEmp.withColumnRenamed(f\"_c{index}\", colName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>razao_social_nome_empresarial</th>\n",
              "      <th>natureza_juridica</th>\n",
              "      <th>qualificacao_do_responsavel</th>\n",
              "      <th>capital_social_da_empresa</th>\n",
              "      <th>porte_da_empresa</th>\n",
              "      <th>ente_federativo_responsavel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306</td>\n",
              "      <td>FRANCAMAR REFRIGERACAO TECNICA S/C LTDA</td>\n",
              "      <td>2240</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1355</td>\n",
              "      <td>BRASILEIRO &amp; OLIVEIRA LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4820</td>\n",
              "      <td>REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...</td>\n",
              "      <td>3034</td>\n",
              "      <td>32</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5347</td>\n",
              "      <td>ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS</td>\n",
              "      <td>2135</td>\n",
              "      <td>50</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6846</td>\n",
              "      <td>BADU E FILHOS TECIDOS LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>4000,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico                      razao_social_nome_empresarial  \\\n",
              "0          306            FRANCAMAR REFRIGERACAO TECNICA S/C LTDA   \n",
              "1         1355                         BRASILEIRO & OLIVEIRA LTDA   \n",
              "2         4820  REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...   \n",
              "3         5347       ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS   \n",
              "4         6846                         BADU E FILHOS TECIDOS LTDA   \n",
              "\n",
              "   natureza_juridica  qualificacao_do_responsavel capital_social_da_empresa  \\\n",
              "0               2240                           49                      0,00   \n",
              "1               2062                           49                      0,00   \n",
              "2               3034                           32                      0,00   \n",
              "3               2135                           50                      0,00   \n",
              "4               2062                           49                   4000,00   \n",
              "\n",
              "   porte_da_empresa ente_federativo_responsavel  \n",
              "0                 1                        None  \n",
              "1                 5                        None  \n",
              "2                 5                        None  \n",
              "3                 5                        None  \n",
              "4                 1                        None  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEmp.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMfPDezDGlH-"
      },
      "outputs": [],
      "source": [
        "estabsColNames = ['cnpj_basico', 'cnpj_ordem', 'cnpj_dv', 'identificador_matriz_filial', 'nome_fantasia', 'situacao_cadastral', 'data_situacao_cadastral', 'motivo_situacao_cadastral', 'nome_da_cidade_no_exterior', 'pais', 'data_de_inicio_atividade', 'cnae_fiscal_principal', 'cnae_fiscal_secundaria', 'tipo_de_logradouro', 'logradouro', 'numero', 'complemento', 'bairro', 'cep', 'uf', 'municipio', 'ddd_1', 'telefone_1', 'ddd_2', 'telefone_2', 'ddd_do_fax', 'fax', 'correio_eletronico', 'situacao_especial', 'data_da_situacao_especial']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a04WKP_dGlH_"
      },
      "outputs": [],
      "source": [
        "for index, colName in enumerate(estabsColNames):\n",
        "    dfEstab = dfEstab.withColumnRenamed(f\"_c{index}\", colName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>cnpj_ordem</th>\n",
              "      <th>cnpj_dv</th>\n",
              "      <th>identificador_matriz_filial</th>\n",
              "      <th>nome_fantasia</th>\n",
              "      <th>situacao_cadastral</th>\n",
              "      <th>data_situacao_cadastral</th>\n",
              "      <th>motivo_situacao_cadastral</th>\n",
              "      <th>nome_da_cidade_no_exterior</th>\n",
              "      <th>pais</th>\n",
              "      <th>...</th>\n",
              "      <th>municipio</th>\n",
              "      <th>ddd_1</th>\n",
              "      <th>telefone_1</th>\n",
              "      <th>ddd_2</th>\n",
              "      <th>telefone_2</th>\n",
              "      <th>ddd_do_fax</th>\n",
              "      <th>fax</th>\n",
              "      <th>correio_eletronico</th>\n",
              "      <th>situacao_especial</th>\n",
              "      <th>data_da_situacao_especial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1879</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>PIRAMIDE M. C.</td>\n",
              "      <td>8</td>\n",
              "      <td>20011029</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2818</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>20081231</td>\n",
              "      <td>71</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3110</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>19971231</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3733</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>20081231</td>\n",
              "      <td>71</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4628</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>EMBROIDERY &amp; GIFT</td>\n",
              "      <td>8</td>\n",
              "      <td>19980429</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7075</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico  cnpj_ordem  cnpj_dv  identificador_matriz_filial  \\\n",
              "0         1879           1       96                            1   \n",
              "1         2818           1       43                            1   \n",
              "2         3110           1        7                            1   \n",
              "3         3733           1       80                            1   \n",
              "4         4628           3       27                            2   \n",
              "\n",
              "       nome_fantasia  situacao_cadastral  data_situacao_cadastral  \\\n",
              "0     PIRAMIDE M. C.                   8                 20011029   \n",
              "1               None                   8                 20081231   \n",
              "2               None                   8                 19971231   \n",
              "3               None                   8                 20081231   \n",
              "4  EMBROIDERY & GIFT                   8                 19980429   \n",
              "\n",
              "   motivo_situacao_cadastral nome_da_cidade_no_exterior  pais  ...  municipio  \\\n",
              "0                          1                       None   NaN  ...       7107   \n",
              "1                         71                       None   NaN  ...       7107   \n",
              "2                          1                       None   NaN  ...       7107   \n",
              "3                         71                       None   NaN  ...       7107   \n",
              "4                          1                       None   NaN  ...       7075   \n",
              "\n",
              "   ddd_1 telefone_1 ddd_2 telefone_2 ddd_do_fax   fax correio_eletronico  \\\n",
              "0   None       None  None       None        NaN  None               None   \n",
              "1   None       None  None       None        NaN  None               None   \n",
              "2   None       None  None       None        NaN  None               None   \n",
              "3   None       None  None       None        NaN  None               None   \n",
              "4   None       None  None       None        NaN  None               None   \n",
              "\n",
              "   situacao_especial data_da_situacao_especial  \n",
              "0               None                       NaN  \n",
              "1               None                       NaN  \n",
              "2               None                       NaN  \n",
              "3               None                       NaN  \n",
              "4               None                       NaN  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEstab.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hR0XZghGlH_"
      },
      "outputs": [],
      "source": [
        "sociosColNames = ['cnpj_basico', 'identificador_de_socio', 'nome_do_socio_ou_razao_social', 'cnpj_ou_cpf_do_socio', 'qualificacao_do_socio', 'data_de_entrada_sociedade', 'pais', 'representante_legal', 'nome_do_representante', 'qualificacao_do_representante_legal', 'faixa_etaria']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjBME0tPGlH_"
      },
      "outputs": [],
      "source": [
        "for index, colName in enumerate(sociosColNames):\n",
        "    dfSoc = dfSoc.withColumnRenamed(f\"_c{index}\", colName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>identificador_de_socio</th>\n",
              "      <th>nome_do_socio_ou_razao_social</th>\n",
              "      <th>cnpj_ou_cpf_do_socio</th>\n",
              "      <th>qualificacao_do_socio</th>\n",
              "      <th>data_de_entrada_sociedade</th>\n",
              "      <th>pais</th>\n",
              "      <th>representante_legal</th>\n",
              "      <th>nome_do_representante</th>\n",
              "      <th>qualificacao_do_representante_legal</th>\n",
              "      <th>faixa_etaria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "      <td>LILIANA PATRICIA GUASTAVINO</td>\n",
              "      <td>***678188**</td>\n",
              "      <td>22</td>\n",
              "      <td>19940725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "      <td>CRISTINA HUNDERTMARK</td>\n",
              "      <td>***637848**</td>\n",
              "      <td>28</td>\n",
              "      <td>19940725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5813</td>\n",
              "      <td>2</td>\n",
              "      <td>CELSO EDUARDO DE CASTRO STEPHAN</td>\n",
              "      <td>***786068**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940516</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5813</td>\n",
              "      <td>2</td>\n",
              "      <td>EDUARDO BERRINGER STEPHAN</td>\n",
              "      <td>***442348**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940516</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14798</td>\n",
              "      <td>2</td>\n",
              "      <td>HANNE MAHFOUD FADEL</td>\n",
              "      <td>***760388**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940609</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico  identificador_de_socio    nome_do_socio_ou_razao_social  \\\n",
              "0          411                       2      LILIANA PATRICIA GUASTAVINO   \n",
              "1          411                       2             CRISTINA HUNDERTMARK   \n",
              "2         5813                       2  CELSO EDUARDO DE CASTRO STEPHAN   \n",
              "3         5813                       2        EDUARDO BERRINGER STEPHAN   \n",
              "4        14798                       2              HANNE MAHFOUD FADEL   \n",
              "\n",
              "  cnpj_ou_cpf_do_socio  qualificacao_do_socio  data_de_entrada_sociedade  \\\n",
              "0          ***678188**                     22                   19940725   \n",
              "1          ***637848**                     28                   19940725   \n",
              "2          ***786068**                     49                   19940516   \n",
              "3          ***442348**                     49                   19940516   \n",
              "4          ***760388**                     49                   19940609   \n",
              "\n",
              "   pais representante_legal nome_do_representante  \\\n",
              "0   NaN         ***000000**                  None   \n",
              "1   NaN         ***000000**                  None   \n",
              "2   NaN         ***000000**                  None   \n",
              "3   NaN         ***000000**                  None   \n",
              "4   NaN         ***000000**                  None   \n",
              "\n",
              "   qualificacao_do_representante_legal  faixa_etaria  \n",
              "0                                    0             7  \n",
              "1                                    0             7  \n",
              "2                                    0             8  \n",
              "3                                    0             5  \n",
              "4                                    0             8  "
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfSoc.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnibIqSUGlH_"
      },
      "source": [
        "## Analisando os dados\n",
        "\n",
        "[Data Types](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.sql.html#data-types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BCEdVduXqLP"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>razao_social_nome_empresarial</th>\n",
              "      <th>natureza_juridica</th>\n",
              "      <th>qualificacao_do_responsavel</th>\n",
              "      <th>capital_social_da_empresa</th>\n",
              "      <th>porte_da_empresa</th>\n",
              "      <th>ente_federativo_responsavel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306</td>\n",
              "      <td>FRANCAMAR REFRIGERACAO TECNICA S/C LTDA</td>\n",
              "      <td>2240</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1355</td>\n",
              "      <td>BRASILEIRO &amp; OLIVEIRA LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4820</td>\n",
              "      <td>REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...</td>\n",
              "      <td>3034</td>\n",
              "      <td>32</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5347</td>\n",
              "      <td>ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS</td>\n",
              "      <td>2135</td>\n",
              "      <td>50</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6846</td>\n",
              "      <td>BADU E FILHOS TECIDOS LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>4000,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico                      razao_social_nome_empresarial  \\\n",
              "0          306            FRANCAMAR REFRIGERACAO TECNICA S/C LTDA   \n",
              "1         1355                         BRASILEIRO & OLIVEIRA LTDA   \n",
              "2         4820  REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...   \n",
              "3         5347       ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS   \n",
              "4         6846                         BADU E FILHOS TECIDOS LTDA   \n",
              "\n",
              "   natureza_juridica  qualificacao_do_responsavel capital_social_da_empresa  \\\n",
              "0               2240                           49                      0,00   \n",
              "1               2062                           49                      0,00   \n",
              "2               3034                           32                      0,00   \n",
              "3               2135                           50                      0,00   \n",
              "4               2062                           49                   4000,00   \n",
              "\n",
              "   porte_da_empresa ente_federativo_responsavel  \n",
              "0                 1                        None  \n",
              "1                 5                        None  \n",
              "2                 5                        None  \n",
              "3                 5                        None  \n",
              "4                 1                        None  "
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEmp.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aocivOoxGlIA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- razao_social_nome_empresarial: string (nullable = true)\n",
            " |-- natureza_juridica: integer (nullable = true)\n",
            " |-- qualificacao_do_responsavel: integer (nullable = true)\n",
            " |-- capital_social_da_empresa: string (nullable = true)\n",
            " |-- porte_da_empresa: integer (nullable = true)\n",
            " |-- ente_federativo_responsavel: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfEmp.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNQJP7E6UsGC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>identificador_de_socio</th>\n",
              "      <th>nome_do_socio_ou_razao_social</th>\n",
              "      <th>cnpj_ou_cpf_do_socio</th>\n",
              "      <th>qualificacao_do_socio</th>\n",
              "      <th>data_de_entrada_sociedade</th>\n",
              "      <th>pais</th>\n",
              "      <th>representante_legal</th>\n",
              "      <th>nome_do_representante</th>\n",
              "      <th>qualificacao_do_representante_legal</th>\n",
              "      <th>faixa_etaria</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "      <td>LILIANA PATRICIA GUASTAVINO</td>\n",
              "      <td>***678188**</td>\n",
              "      <td>22</td>\n",
              "      <td>19940725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>411</td>\n",
              "      <td>2</td>\n",
              "      <td>CRISTINA HUNDERTMARK</td>\n",
              "      <td>***637848**</td>\n",
              "      <td>28</td>\n",
              "      <td>19940725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5813</td>\n",
              "      <td>2</td>\n",
              "      <td>CELSO EDUARDO DE CASTRO STEPHAN</td>\n",
              "      <td>***786068**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940516</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5813</td>\n",
              "      <td>2</td>\n",
              "      <td>EDUARDO BERRINGER STEPHAN</td>\n",
              "      <td>***442348**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940516</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14798</td>\n",
              "      <td>2</td>\n",
              "      <td>HANNE MAHFOUD FADEL</td>\n",
              "      <td>***760388**</td>\n",
              "      <td>49</td>\n",
              "      <td>19940609</td>\n",
              "      <td>NaN</td>\n",
              "      <td>***000000**</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico  identificador_de_socio    nome_do_socio_ou_razao_social  \\\n",
              "0          411                       2      LILIANA PATRICIA GUASTAVINO   \n",
              "1          411                       2             CRISTINA HUNDERTMARK   \n",
              "2         5813                       2  CELSO EDUARDO DE CASTRO STEPHAN   \n",
              "3         5813                       2        EDUARDO BERRINGER STEPHAN   \n",
              "4        14798                       2              HANNE MAHFOUD FADEL   \n",
              "\n",
              "  cnpj_ou_cpf_do_socio  qualificacao_do_socio  data_de_entrada_sociedade  \\\n",
              "0          ***678188**                     22                   19940725   \n",
              "1          ***637848**                     28                   19940725   \n",
              "2          ***786068**                     49                   19940516   \n",
              "3          ***442348**                     49                   19940516   \n",
              "4          ***760388**                     49                   19940609   \n",
              "\n",
              "   pais representante_legal nome_do_representante  \\\n",
              "0   NaN         ***000000**                  None   \n",
              "1   NaN         ***000000**                  None   \n",
              "2   NaN         ***000000**                  None   \n",
              "3   NaN         ***000000**                  None   \n",
              "4   NaN         ***000000**                  None   \n",
              "\n",
              "   qualificacao_do_representante_legal  faixa_etaria  \n",
              "0                                    0             7  \n",
              "1                                    0             7  \n",
              "2                                    0             8  \n",
              "3                                    0             5  \n",
              "4                                    0             8  "
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfSoc.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUXixnpzZPQe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- identificador_de_socio: integer (nullable = true)\n",
            " |-- nome_do_socio_ou_razao_social: string (nullable = true)\n",
            " |-- cnpj_ou_cpf_do_socio: string (nullable = true)\n",
            " |-- qualificacao_do_socio: integer (nullable = true)\n",
            " |-- data_de_entrada_sociedade: integer (nullable = true)\n",
            " |-- pais: integer (nullable = true)\n",
            " |-- representante_legal: string (nullable = true)\n",
            " |-- nome_do_representante: string (nullable = true)\n",
            " |-- qualificacao_do_representante_legal: integer (nullable = true)\n",
            " |-- faixa_etaria: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfSoc.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43jdqE5gGlIA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>cnpj_ordem</th>\n",
              "      <th>cnpj_dv</th>\n",
              "      <th>identificador_matriz_filial</th>\n",
              "      <th>nome_fantasia</th>\n",
              "      <th>situacao_cadastral</th>\n",
              "      <th>data_situacao_cadastral</th>\n",
              "      <th>motivo_situacao_cadastral</th>\n",
              "      <th>nome_da_cidade_no_exterior</th>\n",
              "      <th>pais</th>\n",
              "      <th>...</th>\n",
              "      <th>municipio</th>\n",
              "      <th>ddd_1</th>\n",
              "      <th>telefone_1</th>\n",
              "      <th>ddd_2</th>\n",
              "      <th>telefone_2</th>\n",
              "      <th>ddd_do_fax</th>\n",
              "      <th>fax</th>\n",
              "      <th>correio_eletronico</th>\n",
              "      <th>situacao_especial</th>\n",
              "      <th>data_da_situacao_especial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1879</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>PIRAMIDE M. C.</td>\n",
              "      <td>8</td>\n",
              "      <td>20011029</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2818</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>20081231</td>\n",
              "      <td>71</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3110</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>19971231</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3733</td>\n",
              "      <td>1</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>8</td>\n",
              "      <td>20081231</td>\n",
              "      <td>71</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7107</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4628</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>EMBROIDERY &amp; GIFT</td>\n",
              "      <td>8</td>\n",
              "      <td>19980429</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7075</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico  cnpj_ordem  cnpj_dv  identificador_matriz_filial  \\\n",
              "0         1879           1       96                            1   \n",
              "1         2818           1       43                            1   \n",
              "2         3110           1        7                            1   \n",
              "3         3733           1       80                            1   \n",
              "4         4628           3       27                            2   \n",
              "\n",
              "       nome_fantasia  situacao_cadastral  data_situacao_cadastral  \\\n",
              "0     PIRAMIDE M. C.                   8                 20011029   \n",
              "1               None                   8                 20081231   \n",
              "2               None                   8                 19971231   \n",
              "3               None                   8                 20081231   \n",
              "4  EMBROIDERY & GIFT                   8                 19980429   \n",
              "\n",
              "   motivo_situacao_cadastral nome_da_cidade_no_exterior  pais  ...  municipio  \\\n",
              "0                          1                       None   NaN  ...       7107   \n",
              "1                         71                       None   NaN  ...       7107   \n",
              "2                          1                       None   NaN  ...       7107   \n",
              "3                         71                       None   NaN  ...       7107   \n",
              "4                          1                       None   NaN  ...       7075   \n",
              "\n",
              "   ddd_1 telefone_1 ddd_2 telefone_2 ddd_do_fax   fax correio_eletronico  \\\n",
              "0   None       None  None       None        NaN  None               None   \n",
              "1   None       None  None       None        NaN  None               None   \n",
              "2   None       None  None       None        NaN  None               None   \n",
              "3   None       None  None       None        NaN  None               None   \n",
              "4   None       None  None       None        NaN  None               None   \n",
              "\n",
              "   situacao_especial data_da_situacao_especial  \n",
              "0               None                       NaN  \n",
              "1               None                       NaN  \n",
              "2               None                       NaN  \n",
              "3               None                       NaN  \n",
              "4               None                       NaN  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEstab.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVXz5ZFqY1sW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- cnpj_ordem: integer (nullable = true)\n",
            " |-- cnpj_dv: integer (nullable = true)\n",
            " |-- identificador_matriz_filial: integer (nullable = true)\n",
            " |-- nome_fantasia: string (nullable = true)\n",
            " |-- situacao_cadastral: integer (nullable = true)\n",
            " |-- data_situacao_cadastral: integer (nullable = true)\n",
            " |-- motivo_situacao_cadastral: integer (nullable = true)\n",
            " |-- nome_da_cidade_no_exterior: string (nullable = true)\n",
            " |-- pais: integer (nullable = true)\n",
            " |-- data_de_inicio_atividade: integer (nullable = true)\n",
            " |-- cnae_fiscal_principal: integer (nullable = true)\n",
            " |-- cnae_fiscal_secundaria: string (nullable = true)\n",
            " |-- tipo_de_logradouro: string (nullable = true)\n",
            " |-- logradouro: string (nullable = true)\n",
            " |-- numero: string (nullable = true)\n",
            " |-- complemento: string (nullable = true)\n",
            " |-- bairro: string (nullable = true)\n",
            " |-- cep: integer (nullable = true)\n",
            " |-- uf: string (nullable = true)\n",
            " |-- municipio: integer (nullable = true)\n",
            " |-- ddd_1: string (nullable = true)\n",
            " |-- telefone_1: string (nullable = true)\n",
            " |-- ddd_2: string (nullable = true)\n",
            " |-- telefone_2: string (nullable = true)\n",
            " |-- ddd_do_fax: integer (nullable = true)\n",
            " |-- fax: string (nullable = true)\n",
            " |-- correio_eletronico: string (nullable = true)\n",
            " |-- situacao_especial: string (nullable = true)\n",
            " |-- data_da_situacao_especial: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfEstab.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A75QicR-WYxn"
      },
      "source": [
        "## Modificando os tipos de dados\n",
        "\n",
        "[Functions](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.sql.html#functions)\n",
        "\n",
        "[withColumn](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.withColumn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVElbxNlfFjk"
      },
      "source": [
        "### Convertendo String ➔ Double\n",
        "\n",
        "#### `StringType ➔ DoubleType`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSDekv4rbodk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import DoubleType, StringType\n",
        "from pyspark.sql import functions as f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjbORHHw4M5j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- razao_social_nome_empresarial: string (nullable = true)\n",
            " |-- natureza_juridica: integer (nullable = true)\n",
            " |-- qualificacao_do_responsavel: integer (nullable = true)\n",
            " |-- capital_social_da_empresa: string (nullable = true)\n",
            " |-- porte_da_empresa: integer (nullable = true)\n",
            " |-- ente_federativo_responsavel: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfEmp.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyIP_6ge4ZF4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>razao_social_nome_empresarial</th>\n",
              "      <th>natureza_juridica</th>\n",
              "      <th>qualificacao_do_responsavel</th>\n",
              "      <th>capital_social_da_empresa</th>\n",
              "      <th>porte_da_empresa</th>\n",
              "      <th>ente_federativo_responsavel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306</td>\n",
              "      <td>FRANCAMAR REFRIGERACAO TECNICA S/C LTDA</td>\n",
              "      <td>2240</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1355</td>\n",
              "      <td>BRASILEIRO &amp; OLIVEIRA LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4820</td>\n",
              "      <td>REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...</td>\n",
              "      <td>3034</td>\n",
              "      <td>32</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5347</td>\n",
              "      <td>ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS</td>\n",
              "      <td>2135</td>\n",
              "      <td>50</td>\n",
              "      <td>0,00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6846</td>\n",
              "      <td>BADU E FILHOS TECIDOS LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>4000,00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico                      razao_social_nome_empresarial  \\\n",
              "0          306            FRANCAMAR REFRIGERACAO TECNICA S/C LTDA   \n",
              "1         1355                         BRASILEIRO & OLIVEIRA LTDA   \n",
              "2         4820  REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...   \n",
              "3         5347       ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS   \n",
              "4         6846                         BADU E FILHOS TECIDOS LTDA   \n",
              "\n",
              "   natureza_juridica  qualificacao_do_responsavel capital_social_da_empresa  \\\n",
              "0               2240                           49                      0,00   \n",
              "1               2062                           49                      0,00   \n",
              "2               3034                           32                      0,00   \n",
              "3               2135                           50                      0,00   \n",
              "4               2062                           49                   4000,00   \n",
              "\n",
              "   porte_da_empresa ente_federativo_responsavel  \n",
              "0                 1                        None  \n",
              "1                 5                        None  \n",
              "2                 5                        None  \n",
              "3                 5                        None  \n",
              "4                 1                        None  "
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEmp.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUdfkV6EeCJt"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnpj_basico</th>\n",
              "      <th>razao_social_nome_empresarial</th>\n",
              "      <th>natureza_juridica</th>\n",
              "      <th>qualificacao_do_responsavel</th>\n",
              "      <th>capital_social_da_empresa</th>\n",
              "      <th>porte_da_empresa</th>\n",
              "      <th>ente_federativo_responsavel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>306</td>\n",
              "      <td>FRANCAMAR REFRIGERACAO TECNICA S/C LTDA</td>\n",
              "      <td>2240</td>\n",
              "      <td>49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1355</td>\n",
              "      <td>BRASILEIRO &amp; OLIVEIRA LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4820</td>\n",
              "      <td>REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...</td>\n",
              "      <td>3034</td>\n",
              "      <td>32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5347</td>\n",
              "      <td>ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS</td>\n",
              "      <td>2135</td>\n",
              "      <td>50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6846</td>\n",
              "      <td>BADU E FILHOS TECIDOS LTDA</td>\n",
              "      <td>2062</td>\n",
              "      <td>49</td>\n",
              "      <td>4000.00</td>\n",
              "      <td>1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cnpj_basico                      razao_social_nome_empresarial  \\\n",
              "0          306            FRANCAMAR REFRIGERACAO TECNICA S/C LTDA   \n",
              "1         1355                         BRASILEIRO & OLIVEIRA LTDA   \n",
              "2         4820  REGISTRO DE IMOVEIS, TABELIONATO 1 DE NOTAS E ...   \n",
              "3         5347       ROSELY APARECIDA MONTEIRO CALTABIANO FREITAS   \n",
              "4         6846                         BADU E FILHOS TECIDOS LTDA   \n",
              "\n",
              "   natureza_juridica  qualificacao_do_responsavel capital_social_da_empresa  \\\n",
              "0               2240                           49                      0.00   \n",
              "1               2062                           49                      0.00   \n",
              "2               3034                           32                      0.00   \n",
              "3               2135                           50                      0.00   \n",
              "4               2062                           49                   4000.00   \n",
              "\n",
              "   porte_da_empresa ente_federativo_responsavel  \n",
              "0                 1                        None  \n",
              "1                 5                        None  \n",
              "2                 5                        None  \n",
              "3                 5                        None  \n",
              "4                 1                        None  "
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfEmp = dfEmp.withColumn('capital_social_da_empresa', f.regexp_replace('capital_social_da_empresa', ',', '.'))\n",
        "dfEmp.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsNOpcZoe20V"
      },
      "outputs": [],
      "source": [
        "dfEmp = dfEmp.withColumn('capital_social_da_empresa', dfEmp['capital_social_da_empresa'].cast(DoubleType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qUYxtZSGlIE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- razao_social_nome_empresarial: string (nullable = true)\n",
            " |-- natureza_juridica: integer (nullable = true)\n",
            " |-- qualificacao_do_responsavel: integer (nullable = true)\n",
            " |-- capital_social_da_empresa: double (nullable = true)\n",
            " |-- porte_da_empresa: integer (nullable = true)\n",
            " |-- ente_federativo_responsavel: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfEmp.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp_Zv8tAgcbN"
      },
      "source": [
        "### Convertendo String ➔ Date\n",
        "\n",
        "#### `StringType ➔ DateType`\n",
        "\n",
        "[Datetime Patterns](https://spark.apache.org/docs/3.1.2/sql-ref-datetime-pattern.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRdCvl26o1eC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20200924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20201022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20210215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       data\n",
              "0  20200924\n",
              "1  20201022\n",
              "2  20210215"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([(20200924,), (20201022,), (20210215,)], ['data'])\n",
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OMaiBT16YAX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- data: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4alYEILpRZe"
      },
      "outputs": [],
      "source": [
        "df = df.withColumn('data', f.to_date(df.data.cast(StringType()), 'yyyyMMdd'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxB1k7IGp2vo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-09-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-10-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-02-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         data\n",
              "0  2020-09-24\n",
              "1  2020-10-22\n",
              "2  2021-02-15"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yBmkN9H2-QP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- data: date (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- cnpj_basico: integer (nullable = true)\n",
            " |-- cnpj_ordem: integer (nullable = true)\n",
            " |-- cnpj_dv: integer (nullable = true)\n",
            " |-- identificador_matriz_filial: integer (nullable = true)\n",
            " |-- nome_fantasia: string (nullable = true)\n",
            " |-- situacao_cadastral: integer (nullable = true)\n",
            " |-- data_situacao_cadastral: integer (nullable = true)\n",
            " |-- motivo_situacao_cadastral: integer (nullable = true)\n",
            " |-- nome_da_cidade_no_exterior: string (nullable = true)\n",
            " |-- pais: integer (nullable = true)\n",
            " |-- data_de_inicio_atividade: integer (nullable = true)\n",
            " |-- cnae_fiscal_principal: integer (nullable = true)\n",
            " |-- cnae_fiscal_secundaria: string (nullable = true)\n",
            " |-- tipo_de_logradouro: string (nullable = true)\n",
            " |-- logradouro: string (nullable = true)\n",
            " |-- numero: string (nullable = true)\n",
            " |-- complemento: string (nullable = true)\n",
            " |-- bairro: string (nullable = true)\n",
            " |-- cep: integer (nullable = true)\n",
            " |-- uf: string (nullable = true)\n",
            " |-- municipio: integer (nullable = true)\n",
            " |-- ddd_1: string (nullable = true)\n",
            " |-- telefone_1: string (nullable = true)\n",
            " |-- ddd_2: string (nullable = true)\n",
            " |-- telefone_2: string (nullable = true)\n",
            " |-- ddd_do_fax: integer (nullable = true)\n",
            " |-- fax: string (nullable = true)\n",
            " |-- correio_eletronico: string (nullable = true)\n",
            " |-- situacao_especial: string (nullable = true)\n",
            " |-- data_da_situacao_especial: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfEstab.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgO66CVEUGns"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unable to parse datatype from schema. [Errno 61] Connection refused",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:373\u001b[0m, in \u001b[0;36mDataFrame.schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema \u001b[39m=\u001b[39m cast(\n\u001b[0;32m--> 373\u001b[0m         StructType, _parse_datatype_json_string(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mschema()\u001b[39m.\u001b[39mjson())\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m   called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m   :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[127], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dfEstab \u001b[39m=\u001b[39m dfEstab\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m      2\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdata_situacao_cadastral\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m----> 3\u001b[0m         f\u001b[39m.\u001b[39mto_date(dfEstab\u001b[39m.\u001b[39;49mdata_situacao_cadastral\u001b[39m.\u001b[39mcast(StringType()), \u001b[39m'\u001b[39m\u001b[39myyyyMMdd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     )\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m      5\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdata_de_inicio_atividade\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m         f\u001b[39m.\u001b[39mto_date(dfEstab\u001b[39m.\u001b[39mdata_de_inicio_atividade\u001b[39m.\u001b[39mcast(StringType()), \u001b[39m'\u001b[39m\u001b[39myyyyMMdd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     )\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m      8\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdata_da_situacao_especial\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      9\u001b[0m         f\u001b[39m.\u001b[39mto_date(dfEstab\u001b[39m.\u001b[39mdata_da_situacao_especial\u001b[39m.\u001b[39mcast(StringType()), \u001b[39m'\u001b[39m\u001b[39myyyyMMdd\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:1987\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Column:\n\u001b[1;32m   1978\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1979\u001b[0m \n\u001b[1;32m   1980\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[39m    [Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1987\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns:\n\u001b[1;32m   1988\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name)\n\u001b[1;32m   1990\u001b[0m         )\n\u001b[1;32m   1991\u001b[0m     jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mapply(name)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:1394\u001b[0m, in \u001b[0;36mDataFrame.columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcolumns\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m   1385\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns all column names as a list.\u001b[39;00m\n\u001b[1;32m   1386\u001b[0m \n\u001b[1;32m   1387\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[39m    ['age', 'name']\u001b[39;00m\n\u001b[1;32m   1393\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1394\u001b[0m     \u001b[39mreturn\u001b[39;00m [f\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschema\u001b[39m.\u001b[39mfields]\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:376\u001b[0m, in \u001b[0;36mDataFrame.schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema \u001b[39m=\u001b[39m cast(\n\u001b[1;32m    373\u001b[0m             StructType, _parse_datatype_json_string(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mschema()\u001b[39m.\u001b[39mjson())\n\u001b[1;32m    374\u001b[0m         )\n\u001b[1;32m    375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 376\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnable to parse datatype from schema. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema\n",
            "\u001b[0;31mValueError\u001b[0m: Unable to parse datatype from schema. [Errno 61] Connection refused"
          ]
        }
      ],
      "source": [
        "dfEstab = dfEstab.withColumn(\n",
        "        'data_situacao_cadastral', \n",
        "        f.to_date(dfEstab.data_situacao_cadastral.cast(StringType()), 'yyyyMMdd')\n",
        "    ).withColumn(\n",
        "        'data_de_inicio_atividade', \n",
        "        f.to_date(dfEstab.data_de_inicio_atividade.cast(StringType()), 'yyyyMMdd')\n",
        "    ).withColumn(\n",
        "        'data_da_situacao_especial', \n",
        "        f.to_date(dfEstab.data_da_situacao_especial.cast(StringType()), 'yyyyMMdd')\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L2904mRn5dy"
      },
      "outputs": [
        {
          "ename": "ConnectionRefusedError",
          "evalue": "[Errno 61] Connection refused",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[126], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfEstab\u001b[39m.\u001b[39;49mprintSchema()\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:392\u001b[0m, in \u001b[0;36mDataFrame.printSchema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprintSchema\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Prints out the schema in the tree format.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \n\u001b[1;32m    382\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mschema()\u001b[39m.\u001b[39mtreeString())\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
          ]
        }
      ],
      "source": [
        "dfEstab.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39H5_TRgV0j5"
      },
      "outputs": [
        {
          "ename": "ConnectionRefusedError",
          "evalue": "[Errno 61] Connection refused",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfEstab\u001b[39m.\u001b[39;49mlimit(\u001b[39m5\u001b[39;49m)\u001b[39m.\u001b[39mtoPandas()\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/pyspark/sql/dataframe.py:855\u001b[0m, in \u001b[0;36mDataFrame.limit\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlimit\u001b[39m(\u001b[39mself\u001b[39m, num: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    844\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Limits the result count to the number specified.\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \n\u001b[1;32m    846\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[39m    []\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 855\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mlimit(num)\n\u001b[1;32m    856\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
            "File \u001b[0;32m/usr/local/Cellar/apache-spark/3.3.1/libexec/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
          ]
        }
      ],
      "source": [
        "dfEstab.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NE_Hf6G3gak_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTsUeiapO3Pz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rDRJjed8BzS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv529a0SGgMF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg0lldBjGlIB"
      },
      "source": [
        "# Seleções e consultas\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3q8yA8kgH9G"
      },
      "source": [
        "## Selecionando informações\n",
        " \n",
        "[DataFrame.select(*cols)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.select.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdMi5XrjbNxA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9cgyry3GlIB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ilkFXsIbw9j"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j94bdu9r0ykx"
      },
      "source": [
        "## Faça como eu fiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smUC0SgN0sGc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS3mrMkHZjqX"
      },
      "source": [
        "## Identificando valores nulos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8orupk7E9sfp"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   data\n",
              "0   1.0\n",
              "1   2.0\n",
              "2   3.0\n",
              "3   NaN"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([(1,), (2,), (3,), (None,)], ['data'])\n",
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l4asr_S95MN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+\n",
            "|data|\n",
            "+----+\n",
            "|   1|\n",
            "|   2|\n",
            "|   3|\n",
            "|null|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYjUKTUa_KzT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   data\n",
              "0   1.0\n",
              "1   2.0\n",
              "2   3.0\n",
              "3   NaN"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([(1.,), (2.,), (3.,), (float('nan'),)], ['data'])\n",
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqzQebm7_QAO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+\n",
            "|data|\n",
            "+----+\n",
            "| 1.0|\n",
            "| 2.0|\n",
            "| 3.0|\n",
            "| NaN|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8v6WOpb96qU"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   data\n",
              "0     1\n",
              "1     2\n",
              "2     3\n",
              "3  None"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([('1',), ('2',), ('3',), (None,)], ['data'])\n",
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nokz_PPC994j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+\n",
            "|data|\n",
            "+----+\n",
            "|   1|\n",
            "|   2|\n",
            "|   3|\n",
            "|null|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1wvIzb8-Rpk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i95DWXnV-Usy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f2vmhnQZrod"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlccfXKMavJv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_BjVZKeu_V2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYp2I6NBaz2C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DrHfT6vbSeU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_NMPijDgp97"
      },
      "source": [
        "## Ordenando os dados\n",
        "\n",
        "[DataFrame.orderBy(*cols, **kwargs)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.orderBy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiEEP4eTd9K_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZrd_p7mfFDR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeMk86UGhZvc"
      },
      "source": [
        "## Filtrando os dados\n",
        "\n",
        "[DataFrame.where(condition)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.where.html) ou [DataFrame.filter(condition)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.filter.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6ZHVYBHjPa5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6tE7LiKXT1I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ_FrfbOK-1a"
      },
      "source": [
        "## O comando LIKE\n",
        "\n",
        "[Column.like(other)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.Column.like.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3sMWIEIQLY7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RESTAURANTE DO RUI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Juca restaurantes ltda</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Joca Restaurante</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     data\n",
              "0      RESTAURANTE DO RUI\n",
              "1  Juca restaurantes ltda\n",
              "2        Joca Restaurante"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = spark.createDataFrame([('RESTAURANTE DO RUI',), ('Juca restaurantes ltda',), ('Joca Restaurante',)], ['data'])\n",
        "df.toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfc1p_pEQ1UJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHqcmjIxGlIF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiyZCFaEQPtQ"
      },
      "source": [
        "# Agregações e Junções\n",
        "---\n",
        "\n",
        "[DataFrame.groupBy(*cols)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.groupBy.html)\n",
        "\n",
        "[DataFrame.agg(*exprs)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.agg.html)\n",
        "\n",
        "[DataFrame.summary(*statistics)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.summary.html)\n",
        "\n",
        "> Funções:\n",
        "[approx_count_distinct](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.approx_count_distinct.html) | \n",
        "[avg](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.avg.html) | \n",
        "[collect_list](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.collect_list.html) | \n",
        "[collect_set](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.collect_set.html) | \n",
        "[countDistinct](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.countDistinct.html) | \n",
        "[count](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.count.html) | \n",
        "[grouping](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.grouping.html) | \n",
        "[first](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.first.html) | \n",
        "[last](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.last.html) | \n",
        "[kurtosis](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.kurtosis.html) | \n",
        "[max](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.max.html) | \n",
        "[min](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.min.html) | \n",
        "[mean](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.mean.html) | \n",
        "[skewness](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.skewness.html) | \n",
        "[stddev ou stddev_samp](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.stddev.html) | \n",
        "[stddev_pop](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.stddev_pop.html) | \n",
        "[sum](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.sum.html) | \n",
        "[sumDistinct](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.sumDistinct.html) | \n",
        "[variance ou var_samp](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.variance.html) | \n",
        "[var_pop](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.var_pop.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc6YDFOkywQc"
      },
      "source": [
        "## Sumarizando os dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8p8BS7QQKfS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlAbbR4SdZHw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oOOQPUqNiRZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOCWSMepX5jN"
      },
      "source": [
        "## Juntando DataFrames - Joins\n",
        "\n",
        "[DataFrame.join(*args)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.join.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uklRCkDX4Tf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCMHBCrokoc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDaN4XFQkdsE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyvClbqRHviC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq_pGKucIjri"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWoVxvYKJkC-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta9UsinQJn1w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kki6ZPfNJ_sI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIhL8EKGN09L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrIpShtRN3WK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZ9OYX7NN8SM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdFVRNJeQRua"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSEJMOF5PxGF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qARQXzC71hPq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26U30E70nTew"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq-9n_n2GlIF"
      },
      "source": [
        "## SparkSQL\n",
        "\n",
        "[SparkSession.sql(sqlQuery)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.SparkSession.sql.html)\n",
        "\n",
        "Para saber mais sobre performance: [Artigo - Spark RDDs vs DataFrames vs SparkSQL](https://community.cloudera.com/t5/Community-Articles/Spark-RDDs-vs-DataFrames-vs-SparkSQL/ta-p/246547)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGCFVpPnGlIF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c_OrvMLGlIF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cff25Y3GlIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rj0ADzBfGlIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRxV3Crg1ZFo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0zjZOxM0jzy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0oUrvo4E76z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghAEAvfj0eS3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDM3l-CUGlIJ"
      },
      "source": [
        "# Formas de Armazenamento\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySrkXajNGlIK"
      },
      "source": [
        "## Arquivos CSV\n",
        "\n",
        "[property DataFrame.write](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrame.write.html)\n",
        "\n",
        "[DataFrameWriter.csv(*args)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrameWriter.csv.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1PBgc6kGlIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42_1Y8eW6e2r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD01X0MN6pgp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4KYGLOUe9VN"
      },
      "source": [
        "## Faça como eu fiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ttmS8v1GlIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YvAdU_MGlIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7vmWujGlIK"
      },
      "source": [
        "## Arquivos PARQUET\n",
        "\n",
        "[Apache Parquet](https://parquet.apache.org/)\n",
        "\n",
        "[DataFrameWriter.parquet(*args)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrameWriter.parquet.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd14cXcto9za"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZysCHmzicRo4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9siUUauWdAej"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYsfCfudGlIK"
      },
      "source": [
        "## Particionamento dos dados\n",
        "\n",
        "[DataFrameWriter.partitionBy(*cols)](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.DataFrameWriter.partitionBy.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3lGYb4qRVz3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6Tv9DelGlIL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFAQ-XlHScMr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dveTyKd1VitH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".spark_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "c5b2ab901d88f4846543140d0410d9e785392947c0feb291dee01b3b6d5be827"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
